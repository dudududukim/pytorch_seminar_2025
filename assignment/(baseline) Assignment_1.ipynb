{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a904354",
   "metadata": {},
   "source": [
    "# Assignment #1 Requirements üéØ\n",
    "\n",
    "**Submission:**  \n",
    "- Submit a Jupyter Notebook (`.ipynb`) file.\n",
    "\n",
    "**Your Task:**  \n",
    "- Train a model on your own dataset (e.g., ImageNet1K or FlowerDataset).\n",
    "\n",
    "**Notebook must demonstrate:**\n",
    "1. **Custom Model Declaration** üõ†Ô∏è  \n",
    "    - Define your own model class, including architecture initialization and forward pass.\n",
    "\n",
    "2. **Checkpoint Loading** üíæ  \n",
    "    - Load saved model weights from a checkpoint file into your custom model instance.\n",
    "\n",
    "3. **Dataset & Evaluation** üìä  \n",
    "    - Load the specified dataset and perform model evaluation to demonstrate the trained model's performance.\n",
    "\n",
    "## Submission Instructions üì•\n",
    "\n",
    "You must submit the following files:\n",
    "\n",
    "- **A trained Jupyter Notebook (.ipynb) file**  \n",
    "  (The notebook should include all code and results demonstrating your training process.)\n",
    "\n",
    "- **A model checkpoint file**  \n",
    "  (Save your trained model weights using `torch.save()` or an equivalent method.)\n",
    "\n",
    "Please ensure both files are included in your submission so that your training process and final model can be fully evaluated.\n",
    "\n",
    "**Additional Notes:**  \n",
    "- You can write your own jupyter notebook with brand-new code.\n",
    "- Leave the model definition and dataset loading code as templates or with helpful comments if needed.\n",
    "- After training, save a checkpoint, and include code to load the checkpoint and run inference, so that the grader can easily evaluate your model.\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Duhyeon Kim + Perplexity (GPT4.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ce904",
   "metadata": {},
   "source": [
    "### 1. Import libraries and set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fcfd7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(\"using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cafbac",
   "metadata": {},
   "source": [
    "### 2. Custom Dataset Class (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64aa17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        # Create list of data paths/labels\n",
    "        self.samples = []\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "\n",
    "        # TODO: Collect class names and file paths according to folder structure\n",
    "        classes = sorted(os.listdir(root))\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(classes)}\n",
    "        self.idx_to_class = {idx: cls_name for cls_name, idx in self.class_to_idx.items()}\n",
    "        for cls_name in classes:\n",
    "            cls_folder = os.path.join(root, cls_name)\n",
    "            for fname in os.listdir(cls_folder):\n",
    "                if fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    path = os.path.join(cls_folder, fname)\n",
    "                    self.samples.append((path, self.class_to_idx[cls_name]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c021999f",
   "metadata": {},
   "source": [
    "### 3. Prepare Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6899092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change the paths below to your dataset paths\n",
    "train_root = '../day2/cifar10_images/train'\n",
    "test_root = '../day2/cifar10_images/test'\n",
    "\n",
    "# TODO: Modify transforms as needed\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(...), # Add if needed\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train_root, transform=train_transform)\n",
    "test_dataset = CustomDataset(test_root, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13ec00",
   "metadata": {},
   "source": [
    "### 4. Custom Model Declaration (Blank/Hint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        # TODO: Write your model architecture here\n",
    "        # Example:\n",
    "        # self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "        # self.pool = nn.MaxPool2d(2, 2)\n",
    "        # self.fc1 = nn.Linear(16*16*16, 10)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward computation\n",
    "        # Example:\n",
    "        # x = self.pool(F.relu(self.conv1(x)))\n",
    "        # x = x.view(-1, 16*16*16)\n",
    "        # x = self.fc1(x)\n",
    "        # return x\n",
    "        pass\n",
    "\n",
    "# Day1 Lecture Example Model:\n",
    "\n",
    "# class CustomModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "#         self.pool = nn.MaxPool2d(2, 2)\n",
    "#         self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
    "#         self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead81e92",
   "metadata": {},
   "source": [
    "### 5. Training Loop (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c7addc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.2499\n",
      "Epoch [2/10], Loss: 2.1484\n",
      "Epoch [3/10], Loss: 2.0525\n",
      "Epoch [4/10], Loss: 1.9817\n",
      "Epoch [5/10], Loss: 1.9367\n",
      "Epoch [6/10], Loss: 1.9053\n",
      "Epoch [7/10], Loss: 1.8820\n",
      "Epoch [8/10], Loss: 1.8617\n",
      "Epoch [9/10], Loss: 1.8441\n",
      "Epoch [10/10], Loss: 1.8250\n"
     ]
    }
   ],
   "source": [
    "model = CustomModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 10  # TODO: Change if needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9ee61",
   "metadata": {},
   "source": [
    "### 6. Save Checkpoint, Load Checkpoint, and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ea619e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved!\n",
      "Test Accuracy: 36.58%\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), 'custom_model_ckpt.pth')\n",
    "print(\"Checkpoint saved!\")\n",
    "\n",
    "# For submission: The evaluator should be able to run inference with this code\n",
    "model_loaded = CustomModel().to(device)\n",
    "model_loaded.load_state_dict(torch.load('custom_model_ckpt.pth', map_location=device))\n",
    "model_loaded.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_loaded(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d238fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2f",
   "language": "python",
   "name": "d2f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
